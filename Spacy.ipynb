{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Spacy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taghouti-ghofrane/Complete-Python-3-Bootcamp/blob/master/Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EeY1TC3yX6c",
        "outputId": "9f373dfe-7092-4f91-b24c-c17594ff5a71"
      },
      "source": [
        "# Installing Spacy library\n",
        "\n",
        "!pip install spacy==3.1.1\n",
        "!pip install spacy-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3.1.1\n",
            "  Downloading spacy-3.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 3.6 MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (21.2)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (1.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 36.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (3.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (2.23.0)\n",
            "Collecting thinc<8.1.0,>=8.0.8\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 51.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (1.19.5)\n",
            "Collecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.1.1) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy==3.1.1) (3.6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.1.1) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy==3.1.1) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.1.1) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3.1.1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.1.1) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.8.2 spacy-3.1.1 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n",
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.1.2-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 128 kB/s \n",
            "\u001b[?25hCollecting transformers<4.12.0,>=3.4.0\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (2.4.2)\n",
            "Collecting spacy<4.0.0,>=3.1.3\n",
            "  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 20.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (1.10.0+cu111)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.11.3)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.6.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (21.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.0.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (3.10.0.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (0.3.2)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (8.0.13)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.1.3->spacy-transformers) (4.62.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.1.3->spacy-transformers) (3.6.0)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.1.3->spacy-transformers) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (1.24.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 39.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.12.0,>=3.4.0->spacy-transformers) (4.8.2)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.12.0,>=3.4.0->spacy-transformers) (3.3.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.12.0,>=3.4.0->spacy-transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.1.3->spacy-transformers) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.1.3->spacy-transformers) (2.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.12.0,>=3.4.0->spacy-transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.12.0,>=3.4.0->spacy-transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, spacy-loggers, sacremoses, langcodes, huggingface-hub, transformers, spacy-alignments, spacy, spacy-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.1.1\n",
            "    Uninstalling spacy-3.1.1:\n",
            "      Successfully uninstalled spacy-3.1.1\n",
            "Successfully installed huggingface-hub-0.1.2 langcodes-3.3.0 pyyaml-6.0 sacremoses-0.0.46 spacy-3.2.0 spacy-alignments-0.8.4 spacy-loggers-1.0.1 spacy-transformers-1.1.2 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ff1uGbyYqI",
        "outputId": "d8313afb-e5b4-422e-e4c1-a84d583dbb79"
      },
      "source": [
        "import spacy\n",
        "print(spacy.__version__)  # 3.1.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKGeANG-WCdB",
        "outputId": "f81a88ba-4341-447b-843d-f989b75103b4"
      },
      "source": [
        "# Downloading the spaCy model \"en_core_web_trf\"\n",
        "!python -m spacy download en_core_web_trf"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-trf==3.2.0\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\")': /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\")': /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\")': /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\")': /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream\u001b[0m\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\")': /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream\u001b[0m\n",
            "\u001b[31mERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Max retries exceeded with url: /github-production-release-asset-2e65be/84940268/8af876c9-87a7-4731-8566-bc76828fe39e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211116%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211116T140754Z&X-Amz-Expires=300&X-Amz-Signature=0f0783bc6a3cc4bfdc056d120105fe4a33e9f0df59e70ee1da7f4db1b09251a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=84940268&response-content-disposition=attachment%3B%20filename%3Den_core_web_trf-3.2.0-py3-none-any.whl&response-content-type=application%2Foctet-stream (Caused by ReadTimeoutError(\"HTTPSConnectionPool(host='objects.githubusercontent.com', port=443): Read timed out. (read timeout=15)\"))\n",
            "\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhM8ogBMyhM9"
      },
      "source": [
        "# Importing libraries\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "\n",
        "# Storing docs in binary format\n",
        "from spacy.tokens import DocBin\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZHNRSdpYzcWv",
        "outputId": "5907f97d-dd8c-447c-d42c-c228abe72e77"
      },
      "source": [
        "# Reading the dataset\n",
        "df = pd.read_csv(\"Data1.csv\", encoding='latin-1')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>According to Gran , the company has no plans t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neutral</td>\n",
              "      <td>Technopolis plans to develop in stages an area...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>The international electronic industry company ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>With the new production plant the company woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>According to the company 's updated strategy f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Sentiment                                               Text\n",
              "0   neutral  According to Gran , the company has no plans t...\n",
              "1   neutral  Technopolis plans to develop in stages an area...\n",
              "2  negative  The international electronic industry company ...\n",
              "3  positive  With the new production plant the company woul...\n",
              "4  positive  According to the company 's updated strategy f..."
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kyc2aUot0AOR",
        "outputId": "8992836c-44a8-4af2-a1d6-25186500d60b"
      },
      "source": [
        "df['Text'][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .'"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "PkIxDjoL0t5X",
        "outputId": "6274970d-87ac-4b17-ce20-223e4a1af15e"
      },
      "source": [
        "df['Text'][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Uv5Q7UwB1k-G",
        "outputId": "9f156a79-dbf8-4d22-dbf5-76ceb0afaaa4"
      },
      "source": [
        "df['Text'][1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v98EOI98Pt6C",
        "outputId": "d664759d-5e10-49b6-b3c8-962e11a49f11"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4846, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nx5tSMPozzp"
      },
      "source": [
        "#Splitting the dataset into train and test\n",
        "train = df.sample(frac = 0.8, random_state = 25)\n",
        "test = df.drop(train.index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiMxhl_Io8wZ",
        "outputId": "4eef215d-09f1-4b27-a06a-81b4a4fba64b"
      },
      "source": [
        "# Checking the shape\n",
        "\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3877, 2) (969, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He6ldtVd1yRu",
        "outputId": "ca97ca51-76d0-4ea2-c3ac-c0dfac3a3d69"
      },
      "source": [
        "import spacy\n",
        "nlp=spacy.load(\"en_core_web_trf\")\n",
        "nlp.pipe_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['transformer', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHFe2SngpGDp"
      },
      "source": [
        "#Converting the data into Spacy input format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAqx-b_h4T6Z"
      },
      "source": [
        "\n",
        "train['tuples'] = train.apply(lambda row: (row['Text'],row['Sentiment']), axis=1)\n",
        "train = train['tuples'].tolist()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD_sARxXp13e"
      },
      "source": [
        "\n",
        "test['tuples'] = test.apply(lambda row: (row['Text'],row['Sentiment']), axis=1)\n",
        "test = test['tuples'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PYEezCGg2ak",
        "outputId": "2ddef44f-c667-4340-cfea-b5be0c9e272b"
      },
      "source": [
        "train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Altia 's operating profit jumped to EUR 47 million from EUR 6.6 million .\",\n",
              " 'positive')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11VZaHpGsE0L"
      },
      "source": [
        "def document(data):\n",
        "  text = []\n",
        "  for doc, label in nlp.pipe(data, as_tuples = True):\n",
        "    if (label=='positive'):\n",
        "      doc.cats['positive'] = 1\n",
        "      doc.cats['negative'] = 0\n",
        "      doc.cats['neutral']  = 0\n",
        "    elif (label=='negative'):\n",
        "      doc.cats['positive'] = 0\n",
        "      doc.cats['negative'] = 1\n",
        "      doc.cats['neutral']  = 0\n",
        "    else:\n",
        "      doc.cats['positive'] = 0\n",
        "      doc.cats['negative'] = 0\n",
        "      doc.cats['neutral']  = 1\n",
        "    text.append(doc)\n",
        "  \n",
        "  return(text)\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48F5fqu7mu7n",
        "outputId": "d86339f8-a97a-4a27-ad28-f5a80a5851cd"
      },
      "source": [
        "# Calculate the time for converting into binary document for train dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the train dataset into function 'document'\n",
        "train_docs = document(train)\n",
        "\n",
        "#Creating binary document using DocBin function in spaCy\n",
        "doc_bin = DocBin(docs = train_docs)\n",
        "\n",
        "#Saving the binary document as train.spacy\n",
        "doc_bin.to_disk(\"train.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for train dataset\n",
        "print('Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duration: 0:06:59.525907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12XS9bEjqeJ2",
        "outputId": "0f27b647-68c7-42ff-8d92-391c5fd26e89"
      },
      "source": [
        "# Calculate the time for converting into binary document for test dataset\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "#passing the test dataset into function 'document'\n",
        "test_docs = document(test)\n",
        "doc_bin = DocBin(docs = test_docs)\n",
        "doc_bin.to_disk(\"valid.spacy\")\n",
        "end_time = datetime.now()\n",
        "\n",
        "#Printing the time duration for test dataset\n",
        "print('Duration: {}'.format(end_time - start_time))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duration: 0:01:42.256281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hYshoyZgU30"
      },
      "source": [
        "https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8ff0JOnkW1O",
        "outputId": "bb8c367b-feb8-4758-f5f8-9bc0eebf275a"
      },
      "source": [
        "#Converting base configuration into full config file\n",
        "\n",
        "!python -m spacy init fill-config ./base_config.cfg ./config.cfg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K0rqecNu15Q",
        "outputId": "f9692c60-f1cb-4e87-92e4-dec6b290f8a0"
      },
      "source": [
        "start_time = datetime.now()\n",
        "\n",
        "!python -m spacy train config.cfg --verbose  --gpu-id 0 --output ./output_updated\n",
        "\n",
        "end_time = datetime.now()\n",
        "\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2021-08-20 02:21:36,684] [INFO] Set up nlp object from config\n",
            "[2021-08-20 02:21:36,693] [DEBUG] Loading corpus from path: test.spacy\n",
            "[2021-08-20 02:21:36,694] [DEBUG] Loading corpus from path: train.spacy\n",
            "[2021-08-20 02:21:36,694] [INFO] Pipeline: ['transformer', 'textcat']\n",
            "[2021-08-20 02:21:36,698] [INFO] Created vocabulary\n",
            "[2021-08-20 02:21:36,699] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2021-08-20 02:22:02,887] [INFO] Initialized pipeline components: ['transformer', 'textcat']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "[2021-08-20 02:22:02,896] [DEBUG] Loading corpus from path: test.spacy\n",
            "[2021-08-20 02:22:02,897] [DEBUG] Loading corpus from path: train.spacy\n",
            "[2021-08-20 02:22:02,930] [DEBUG] Removed existing output directory: output_updated/model-best\n",
            "[2021-08-20 02:22:02,938] [DEBUG] Removed existing output directory: output_updated/model-last\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'textcat']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS TEXTCAT  CATS_SCORE  SCORE \n",
            "---  ------  -------------  ------------  ----------  ------\n",
            "  0       0           0.00          0.03        0.00    0.00\n",
            "  3     200           0.07         37.74       80.34    0.80\n",
            "  6     400           0.38         13.67       85.42    0.85\n",
            " 10     600           0.51          5.09       85.71    0.86\n",
            " 13     800           0.04          0.07       84.87    0.85\n",
            " 17    1000           0.17          0.37       82.75    0.83\n",
            " 20    1200           0.03          0.53       84.53    0.85\n",
            " 24    1400           0.02          0.25       83.57    0.84\n",
            " 27    1600           0.01          0.02       82.53    0.83\n",
            " 31    1800           0.01          0.03       85.29    0.85\n",
            " 34    2000           0.01          0.02       84.97    0.85\n",
            " 38    2200           0.47          5.00       83.15    0.83\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output_updated/model-last\n",
            "Duration: 0:37:01.842649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjua8pn8u18I"
      },
      "source": [
        "text = \"Australia’s largest airline temporarily lays off 2,500 employees\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01JYT1aiu1__",
        "outputId": "cf520e9c-32e7-4270-a0aa-30e6496efbe1"
      },
      "source": [
        "#Test the data from the best model\n",
        "nlp = spacy.load(\"output_updated/model-best\")\n",
        "demo = nlp(text)\n",
        "print(demo.cats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'positive': 0.0011619756696745753, 'negative': 0.9965638518333435, 'neutral': 0.0022742082364857197}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrGG3yVXu2GB",
        "outputId": "a0bf976b-7ba3-4971-933a-b3a874f9862d"
      },
      "source": [
        "text1 = \"Apple earnings: Huge iPhone 12 sales beat analyst expectations\"\n",
        "demo = nlp(text1)\n",
        "print(demo.cats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'positive': 0.998343825340271, 'negative': 0.0014156486140564084, 'neutral': 0.00024052616208791733}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfAunRFxZBvZ",
        "outputId": "17f68b75-c783-45f4-88a0-556b752167e5"
      },
      "source": [
        "text2 = \"Tata Group is looking to enter semiconductor manufacturing as part of its plans to ramp up its presence in the electronics space.\"\n",
        "demo = nlp(text2)\n",
        "print(demo.cats)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'positive': 0.815325140953064, 'negative': 0.0041560824029147625, 'neutral': 0.1805187314748764}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}